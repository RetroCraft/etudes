\documentclass[notes]{agony}
\title{Linear Algebra (Hoffman \& Kunze) Exercises}

\begin{document}
\thispagestyle{firstpage}
\renewcommand{\contentsname}{Exercises\\{\Large from Hoffman \& Kunze, \emph{Linear Algebra}, 2nd ed.}}
\tableofcontents

\chapter{Linear Equations}
\section{Fields}\label{sec:fields}
Notational note: Hoffman \& Kunze prefer italic $F$ to blackboard $\F$.

\section{Systems of Linear Equations}

\begin{xca}
  Verify that the set of complex numbers described in Example 1.2.4 is a subfield of $C$.
\end{xca}
\begin{prf}
  Consider the set of complex numbers $S$ of the form $x + y\sqrt2$ for rational $x$ and $y$,
  along with complex addition and multiplication.

  Both 0 and 1 can be expressed as $0_S = 0+0\sqrt2$ and $1_S = 1 + 0\sqrt2$.

  Let $a = x + y\sqrt2$ and $b = w + z\sqrt2$ be elements of $S$.
  Then, it follows that $a+b = (x+w) + (y+z)\sqrt2$, $-a = (-x) + (-y)\sqrt2$
  and $ab = (xw + 2yz) + (wy + xz)\sqrt2$ are also in $S$ by properties of the field of rationals.
  Finally, if $a \neq 0$, then
  \[ a^{-1} = \frac{1}{x+y\sqrt2} = \frac{x-y\sqrt2}{x^2-2y^2} = \frac{x}{x^2-2y^2} + \frac{-y}{x^2-2y^2}\sqrt2 \]
  which is in $S$.
  Therefore, $S$ is a subfield of $C$.
\end{prf}

\begin{xca}\label{xca:sysequiv}
  Let $F$ be the field of complex numbers.
  Are the following two systems of linear equations equivalent?
  If so, express each equation in each system as a linear combination of the equations in the other system.
  \[ \systeme{x_1-x_2=0, 2x_1+x_2=0} \qquad \systeme{3x_1+x_2=0, x_1+x_2=0} \]
\end{xca}
\begin{prf}
  They are equivalent. The first system is
  \begin{align*}
    x_1 - x_2  & = (3x_1 + x_2) - 2(x_1 + x_2)                \\
    2x_1 + x_2 & = \tfrac12(3x_1 + x_2) + \tfrac12(x_1 + x_2)
  \end{align*}
  and the second system is
  \begin{align*}
    3x_1 + x_2 & = \tfrac14(x_1 - x_2) + \tfrac34(2x_1 + x_2)  \\
    x_1 + x_2  & = -\tfrac13(x_1 - x_2) + \tfrac23(2x_1 + x_2)
  \end{align*}
  Since they are linear combinations of each other, they are equivalent.
\end{prf}

\begin{xca}
  Test the following systems of equations as in \Cref{xca:sysequiv}.
  \[
    \systeme{-x_1+x_2+4x_3=0, x_1+3x_2+8x_3=0, \frac12x_1+x_2+\frac52x_3=0}
    \qquad
    \systeme{x_1-x_3=0, x_2+3x_3=0}
  \]
\end{xca}
\begin{prf}
  They are equivalent and we can show this by creating linear combinations:
  \begin{align*}
    -x_1 + x_2 + 4x_3               & = -(x_1 - x_3) + (x_2 + 3x_3)        \\
    x_1 + 3x_2 + 8x_3               & = (x_1 - x_3) + 3(x_2 + 3x_3)        \\
    \tfrac12x_1 + x_2 + \tfrac52x_3 & = \tfrac12(x_1 - x_3) + (x_2 + 3x_3)
  \end{align*}
  and, eliminating using the above,
  \begin{align*}
    x_1 - x_3  & = -\tfrac34(-x_1 + x_2 + 4x_3) + \tfrac14(\tfrac12x_1 + x_2 + \tfrac52x_3) \\
    x_2 - 3x_3 & = \tfrac14(-x_1 + x_2 + 4x_3) + \tfrac14(\tfrac12x_1 + x_2 + \tfrac52x_3)
  \end{align*}
  Since they are linear combinations of each other, they are equivalent.
\end{prf}

\begin{xca}
  Test the following systems as in \Cref{xca:sysequiv}.
  \[
    \systeme[x_1x_2x_3x_4]{2x_1 + {(-1+i)}x_2 + x_4 = 0, 3x_2 - 2ix_3 + 5x_4 = 0}
    \qquad
    \systeme[x_1x_2x_3x_4]{{(1+\frac{i}{2})}x_1 + 8x_2 - ix_3 - x_4 = 0, \frac{2}{3}x_1 - \frac{1}{2}x_2 + x_3 + 7x_4 = 0}
  \]
\end{xca}
\begin{prf}
  They are not equivalent.
  Suppose for a contradiction that we may write the first equation of the second system as
  a linear combination $a$ and $b$ of the two equations from the first system:
  \[ {(1+\tfrac{i}{2})}x_1 + 8x_2 - ix_3 - x_4 = (2a)x_1 + (2(-1+i)a + 3b)x_2 - (2ib)x_3 + (a + 5b)x_4 \]
  Equating like terms, we have $2a = 1+\frac{i}{2}$ so $a = \frac{1}{2}+\frac{i}{4}$.
  Likewise, $2ib = i$ so $b = \frac{1}{2}$.
  However, $a + 5b = 3 + \frac{i}{4}$ which is not equal to $-1$.
  Therefore, no such $a$ and $b$ can exist.
\end{prf}

\begin{xca}
  Let $F$ be a set which contains exactly two elements, 0 and 1.
  Define an addition and multiplication by the tables:
  \begin{center}
    \begin{tabular}{C|CC}
      + & 0 & 1 \\ \hline 0 & 0 & 1 \\ 1 & 1 & 0
    \end{tabular}
    \qquad
    \begin{tabular}{C|CC}
      \cdot & 0 & 1 \\ \hline 0 & 0 & 0 \\ 1 & 0 & 1
    \end{tabular}
  \end{center}
  Verify that the set $F$, together with these two operations, is a field.
\end{xca}
\begin{prf}
  We prove the nine properties from \Cref{sec:fields}:
  \begin{enumerate}
    \item Consider the only case of distinct $x$ and $y$ in $F$, $0 + 1 = 1 + 0 = 1$.
    \item Exhaust the 8 cases:
          \begin{align*}
            0 + (0 + 0) = (0 + 0) + 0 = 0 \\
            0 + (0 + 1) = (0 + 0) + 1 = 1 \\
            0 + (1 + 0) = (0 + 1) + 0 = 1 \\
            0 + (1 + 1) = (0 + 1) + 1 = 0 \\
            1 + (0 + 0) = (1 + 0) + 0 = 1 \\
            1 + (0 + 1) = (1 + 0) + 1 = 0 \\
            1 + (1 + 0) = (1 + 1) + 0 = 0 \\
            1 + (1 + 1) = (1 + 1) + 1 = 1
          \end{align*}
    \item Let $0_F=0$. Then, $0 + 0 = 0$ and $0 + 1 = 1$.
    \item We define $-0 = 0$ and $-1 = 1$ so that $0 + (-0) = 0$ and $1 + (-1) = 1$.
    \item Again, for the only case of distinct values, $0 \cdot 1 = 1 \cdot 0 = 0$.
    \item Exhaust again the 8 cases:
          \begin{align*}
            0 \cdot (0 \cdot 0) = (0 \cdot 0) \cdot 0 = 0 \\
            0 \cdot (0 \cdot 1) = (0 \cdot 0) \cdot 1 = 0 \\
            0 \cdot (1 \cdot 0) = (0 \cdot 1) \cdot 0 = 0 \\
            0 \cdot (1 \cdot 1) = (0 \cdot 1) \cdot 1 = 0 \\
            1 \cdot (0 \cdot 0) = (1 \cdot 0) \cdot 0 = 0 \\
            1 \cdot (0 \cdot 1) = (1 \cdot 0) \cdot 1 = 0 \\
            1 \cdot (1 \cdot 0) = (1 \cdot 1) \cdot 0 = 0 \\
            1 \cdot (1 \cdot 1) = (1 \cdot 1) \cdot 1 = 1
          \end{align*}
    \item Let $1_F=1$ so $0 \cdot 1 = 0$ and $1 \cdot 1 = 1$.
    \item The only non-zero element is 1, and $1 \cdot 1 = 1$, so define $1^{-1} = 1$.
    \item Exhaustion! If $x=0$, then the result is 0.
          If $y = z$, then we have $1(1 + 1) = 1(0 + 0) = 1(0) = 0$.
          Otherwise, WLOG since we have property 1, we have $1(1 + 0) = 1(1) = 1$.
  \end{enumerate}
  Therefore, $(F,+,\cdot)$ is a field.
\end{prf}

\begin{xca}\label{xca:homeq}
  Prove that if two homogenous systems of linear equations in two unknowns have the same solutions,
  then they are equivalent.
\end{xca}
\begin{prf}
  Represent two homogenous linear systems $a$ and $b$ in two unknowns, $x$ and $y$, as
  \begin{alignat*}{6}
    a_{11}x & +      & a_{12}y = 0 & \qquad & b_{11}x & +      & b_{12}y = 0 \\
    a_{21}x & +      & a_{22}y = 0 &        & b_{21}x & +      & b_{22}y = 0 \\
            & \vdots &             &        &         & \vdots &             \\
    a_{k1}x & +      & a_{k2}y = 0 &        & b_{k1}x & +      & b_{k2}y = 0
  \end{alignat*}
  Now, suppose that these systems share the same solutions.
  As systems of lines in $R^2$, the solution set is either a point or a line.
  If it is a line, then all equations are scalar multiples of that line.
  It immediately follows that the systems are equivalent.

  If the solution set is a point, the point must be the origin.
  In fact, the first system is uniquely determined by the first two equations which are not multiples of each other.
  Suppose WLOG that those are the first two equations.
  Let $i$ be arbitrary and solve for $m$ and $n$ such that
  $b_{i1}x + b_{i2}y = (ma_{11} + na_{21})x + (ma_{12} + na_{22})y$.
  Equating coefficients, $b_{i1} = ma_{11} + na_{21}$ and $b_{i2} = ma_{12} + na_{22}$.
  Then, solving and simplifying,
  \[
    m = \frac{a_{22}b_{i1} - a_{12}b_{i2}}{a_{11}a_{22}-a_{12}a_{21}}
    \qq{and}
    n = \frac{a_{11}b_{i2} - a_{21}b_{i1}}{a_{11}a_{22}-a_{12}a_{21}}.
  \]
  These are well-defined if and only if $a_{11}a_{22} \neq a_{12}a_{21}$, or equivalently,
  if $\frac{a_{11}}{a_{21}} \neq \frac{a_{12}}{a_{22}}$.
  However, this is identical to saying that the first two equations are linearly independent.
  Therefore, $m$ and $n$ exist for every $i$, and the systems are equivalent.
\end{prf}

\begin{xca}\label{xca:ratsf}
  Prove that each subfield of the field of complex numbers contains every rational number.
\end{xca}
\begin{prf}
  Let $F$ be a subfield of $C$ and $r$ be a rational number.
  By definition, we may write $r = \frac{p}{q}$ for integers $p$ and $q$.

  As a subfield of $C$, $0$ and $1$ are in $F$.
  Then, $F$ also contains $1+1 = 2$.
  It follows inductively that $F$ contains all positive integers.
  Likewise, $F$ contains the additive inverse of all its elements.
  Therefore, all negative integers are included.
  It follows that $p$ and $q$ are in $F$.

  We also know that $F$ contains multiplicative inverses, so $q^{-1}$ is in $F$.
  Finally, $F$ is closed under multiplication, so $pq^{-1} = r$ is in $F$, completing the proof.
\end{prf}

\begin{xca}
  Prove that each field of characteristic zero contains a copy of the rational number field.
\end{xca}
\begin{prf}
  As in \Cref{xca:ratsf}, it suffices to embed the integers.
  Let $(F, +_F, \cdot_F)$ be a field of characteristic zero and $n$ be a non-negative integer.
  Then, there is an additive identity $1_F$.
  Let $n_F = 1_F + 1_F + \dotsb + 1_F$ with $|n|$ copies of $1_F$.
  If $n = 0$, let $0_F$ be the multiplicative identity.
  Since $F$ has characteristic zero, this is a distinct value for any $n$.
  Now, let $-n_F$ be the additive inverse of $n_F$.
  It follows that $n \mapsto n_F$ is a bijection that embeds $Z$ in $F$.

  We now apply multiplicative inverses and closure to find that for any $r = \frac{p}{q}$,
  we may write $r \mapsto r_F$ where $r_F = p_F q_F^{-1}$, embedding $Q$ in $F$.
\end{prf}

\section{Matrices and Row Operations}

\begin{xca}
  Find all solutions to the system of equations
  \[ \systeme[x_1x_2]{{(1-i)}x_1 - ix_2 = 0, 2x_1 + {(1-i)}x_2 = 0} \]
\end{xca}
\begin{sol}
  We express the solutions to $AX = 0$ by row-reducing $A = \mqty[1-i&-i\\2&i-1]$:
  \[
    \mqty[1-i&-i\\2&i-1]
    \xto{R_1 - \frac{1-i}{2}R_2} \mqty[0&0\\2&i-1]
    \xto{R_1 \harr R_2} \mqty[2&i-1\\0&0]
    \xto{\frac12 R_1} \mqty[1&\frac{i-1}{2}\\0&0]
  \]
  Therefore, the solutions are $(c, \frac{i-1}{2}c)$ for any $c$.
\end{sol}

\begin{xca}
  If \[ A = \mqty[3&-1&2 \\ 2&1&1 \\ 1&-3&0] \] find all solutions of $AX = 0$ by row-reducing $A$.
\end{xca}
\begin{sol}
  Row-reduce $A$:
  \begin{equation*}
    \begin{split}
      \mqty[3&-1&2 \\ 2&1&1 \\ 1&-3&0]
      & \xto{R_1 - 3R_3} \mqty[0&8&2 \\ 2&1&1 \\ 1&-3&0]
      \xto{R_2 - 2R_3} \mqty[0&8&2 \\ 0&7&1 \\ 1&-3&0]
      \xto{R_1 \harr R_3} \mqty[1&-3&0 \\ 0&7&1 \\ 0&8&2] \\
      & \xto{R_2 - \frac12 R_3} \mqty[1&-3&0 \\ 0&3&0 \\ 0&8&2]
      \xto{R_1 + R_3} \mqty[1&0&0 \\ 0&3&0 \\ 0&8&2]
      \xto{R_3 - \frac83 R_2} \mqty[1&0&0 \\ 0&3&0 \\ 0&0&2]
    \end{split}
  \end{equation*}
  which after a few scalar multiplications is the identity matrix.
  Therefore, $(0,0,0)$ is the only solution.
\end{sol}

\begin{xca}
  If \[ A = \mqty[6&-4&0 \\ 4&-2&0 \\ -1&0&3] \]
  find all solutions of $AX = 2X$ and all solutions of $AX = 3X$.
  (The symbol $cX$ denotes the matrix each entry of which is $c$ times the corresponding entry of $X$.)
\end{xca}
\begin{sol}
  We can represent the matrix equation $AX = 2X$ with the system
  \[ \systeme{6x - 4y = 2x, 4x - 2y = 2y, -x + 3z = 2z} \]
  which can be simplified to the homogenous system
  \[ \systeme{4x - 4y = 0, 4x - 4y = 0, -x + z = 0} \]
  or, equivalently, $\mqty[4&-4&0 \\ 4&-4&0 \\ -1&0&1]X = 0$. We now row-reduce:
  \begin{equation*}
    \begin{split}
      \mqty[4&-4&0 \\ 4&-4&0 \\ -1&0&1]
      & \xto{R_2 - R_1} \mqty[4&-4&0 \\ 0&0&0 \\ -1&0&1]
      \xto{R_1 + 4R_3} \mqty[0&-4&4 \\ 0&0&0 \\ -1&0&1]
      \xto{\frac14 R_1} \mqty[0&-1&1 \\ 0&0&0 \\ -1&0&1] \\
      & \xto{-R_1 \harr -R_3} \mqty[1&0&-1 \\ 0&0&0 \\ 0&1&-1]
      \xto{R_2 \harr R_3} \mqty[1&0&-1 \\ 0&1&-1 \\ 0&0&0]
    \end{split}
  \end{equation*}
  This is equivalent to the equations $x - y = 0$ and $y - z = 0$, so $x = y = z$, that is,
  the solutions are of the form $(c,c,c)$ for some $c$.

  We now do the same with $AX = 3X$, giving the system
  \[
    \systeme{6x - 4y = 3x, 4x - 2y = 3y, -x + 3z = 3z}
    \iff
    \systeme{3x - 4y = 0, 4x - 5y = 0, -x = 0}
  \]
  By inspection, $x = 0$, which implies $y = 0$, so the solution is $(0,0,c)$ for some $c$.
\end{sol}

\begin{xca}
  Find a row-reduced matrix which is row-equivalent to
  \[ A = \mqty[i&-(1+i)&0 \\ 1&-2&1 \\ 1&2i&-1] \]
\end{xca}
\begin{sol}
  We row-reduce by elementary row operations:
  \begin{equation*}
    \begin{split}
      \mqty[i&-(1+i)&0 \\ 1&-2&1 \\ 1&2i&-1]
      & \xto{R_2 + iR_1} \mqty[i&-1-i&0 \\ 0&-1-i&1 \\ 1&2i&-1]
      \xto{R_3 + iR_1} \mqty[i&-1-i&0 \\ 0&-1-i&1 \\ 0&1+i&-1] \\
      & \xto{R_1 + R_3} \mqty[i&0&-1 \\ 0&-1-i&1 \\ 0&1+i&-1]
      \xto{R_3 + R_2} \mqty[i&0&-1 \\ 0&-1-i&1 \\ 0&0&0] \\
      & \xto{-iR_1} \mqty[1&0&i \\ 0&-1-i&1 \\ 0&0&0]
      \xto{-\frac{1-i}{2}R_2} \mqty[1&0&i \\ 0&1&-\frac{1-i}{2} \\ 0&0&0]
    \end{split}
  \end{equation*}
  which is in row-reduced form.
\end{sol}

\begin{xca}
  Prove that the following two matrices are not row-equivalent:
  \[ A = \mqty[2&0&0 \\ a&-1&0 \\ b&c&3] \qq{and} B = \mqty[1&1&2 \\ -2&0&1 \\ 1&3&5] \]
\end{xca}
\begin{sol}
  We row-reduce the two matrices and compare them.
  Consider matrix $A$:
  \begin{equation*}
    \begin{split}
      A & \xto{\frac12 R_1} \mqty[1&0&0 \\ a&-1&0 \\ b&c&3]
      \xto{R_2 - aR_1} \mqty[1&0&0 \\ 0&-1&0 \\ b&c&3]
      \xto{-R_2} \mqty[1&0&0 \\ 0&1&0 \\ b&c&3] \\
      & \xto{R_3 - bR_1} \mqty[1&0&0 \\ 0&1&0 \\ 0&c&3]
      \xto{R_3 - cR_2} \mqty[1&0&0 \\ 0&1&0 \\ 0&0&3]
      \xto{\frac13 R_3} \mqty[1&0&0 \\ 0&1&0 \\ 0&0&1]
    \end{split}
  \end{equation*}
  Therefore, the equation $AX = 0$ has one solution $(0,0,0)$.

  Now, consider matrix $B$:
  \begin{equation*}
    \begin{split}
      B & \xto{R_2 + 2R_1} \mqty[1&1&2 \\ 0&2&3 \\ 1&3&5]
      \xto{R_3 - R_1} \mqty[1&1&2 \\ 0&2&3 \\ 0&2&3]
      \xto{R_3 - R_2} \mqty[1&1&2 \\ 0&2&3 \\ 0&0&0] \\
      & \xto{\frac12 R_2} \mqty[1&1&2 \\ 0&1&\frac32 \\ 0&0&0]
      \xto{R_1 - R_2} \mqty[1&0&\frac12 \\ 0&1&\frac32 \\ 0&0&0]
    \end{split}
  \end{equation*}
  Therefore, the equation $BX = 0$ has the solutions $(-\frac12c, -\frac32c, c)$ for any $c$.

  Since the solution sets are not equivalent, the matrices are not row-equivalent.
\end{sol}

\begin{xca}
  Let \[ A = \mqty[a&b\\c&d] \] be a $2 \times 2$ matrix with complex entries.
  Suppose that $A$ is row-reduced and also that $a+b+c+d=0$.
  Prove that there are exactly three such matrices.
\end{xca}
\begin{prf}
  For $A$ to be row-reduced, the first row is all zero, begins with a 1, or is $\mqty[0&1]$.

  If the first row is zero ($a = 0$ and $b = 0$), then $c+d = 0$.
  Likewise, the second row must either be zero (in which case $c = d = 0$),
  begin with a 1 (in which case $c = 1$ and $d = -1$),
  or be $\mqty[0&1]$ (but $c+d = 0$).
  This gives two options: $A = \mqty[0&0\\0&0]$ and $\mqty[0&0\\1&-1]$.

  If the first row begins with 1, then $c = 0$ and $b+d = -1$.
  Again, the second row is either zero (so $b = -1$ and $d = 0$),
  begin with a 1 (but $c = 0$),
  or be $\mqty[0&1]$ (but then $a$ cannot be 1).
  This also gives two options: $A = \mqty[0&0\\0&0]$ and $\mqty[1&-1\\0&0]$.

  Finally, if the first row is $\mqty[0&1]$, the second row must be $\mqty[0&0]$,
  but then $a+b+c+d \neq 0$.

  Therefore, there are only three matrices $A$, namely,
  $\mqty[0&0\\0&0]$, $\mqty[1&-1\\0&0]$, and $\mqty[0&0\\1&-1]$.
\end{prf}

\begin{xca}
  Prove that the interchange of two rows of a matrix can be accomplished by
  a finite sequence of elementary row operations of the other two types.
\end{xca}
\begin{prf}
  Let $A$ be a matrix with rows $R_1, R_2, \dotsc, R_n$.
  Without loss of generality, we interchange $R_1 \harr R_2$.

  We represent the matrix as $A = \mqty[R_1 \\ R_2 \\ \vdots \\ R_n]$ and row-reduce:
  \begin{equation*}
    \mqty[R_1 \\ R_2 \\ \vdots \\ R_n]
    \xto{R_1 + R_2} \mqty[R_1 + R_2 \\ R_2 \\ \vdots \\ R_n]
    \xto{R_2 - R_1} \mqty[R_1 + R_2 \\ -R_1 \\ \vdots \\ R_n]
    \xto{R_1 + R_2} \mqty[R_2 \\ -R_1 \\ \vdots \\ R_n]
    \xto{-R_2} \mqty[R_2 \\ R_1 \\ \vdots \\ R_n]
  \end{equation*}
  completing the proof.
\end{prf}

\begin{xca}
  Consider the system of equations $AX = 0$ where \[ A = \mqty[a&b \\ c&d] \]
  is a $2 \times 2$ matrix over the field $F$. Prove the following:
  \setlength\parskip{0pt}
  \begin{enumerate}[(a)]
    \item If every entry of $A$ is 0, then every pair $(x_1, x_2)$ is a solution of $AX = 0$.
    \item If $ad-bc \neq 0$, the system $AX = 0$ has only the trivial solution $x_1 = x_2 = 0$.
    \item If $ad-bc = 0$ and some entry of $A$ is different from 0,
          then there is a solution $(x_1^0, x_2^0)$ such that
          $(x_1, x_2)$ is a solution if and only if there is a scalar $y$ such that
          $x_1 = yx_1^0$ and $x_2 = yx_2^0$.
  \end{enumerate}
\end{xca}
\begin{prf}
  Suppose that every entry of $A$ is zero.
  Then, $AX = 0$ is equivalent to the system $0x_1 + 0x_2 = 0$ and $0x_1 + 0x_2 = 0$.
  Both equations simplify to $0 = 0$.
  Therefore, the solution set is $(x_1, x_2)$ for any such pair, as desired in (a).

  Otherwise, suppose that $ad - bc \neq 0$.
  We can then apply the generic solution for a linear system in two equations with two unknowns
  (see \Cref{xca:homeq}):
  \[ x_1 = \frac{d(0) - b(0)}{ad - bc} = 0 \qq{and} x_2 = \frac{a(0) - c(0)}{ad - bc} = 0 \]
  as desired in (b).

  Finally, suppose that $ad - bc = 0$ and some entry of $A$ is non-zero.
  We take without loss of generality (through row reduction and variable symmetry) that $a \neq 0$.
  Then, we can say $d = \frac{bc}{a}$.
  It follows that $\frac{c}{a}(ax_1 + bx_2) = cx_1 + dx_2$.
  Therefore, the first equation implies the second.

  Now, the first equation is equivalently expressed $x_1 = -\frac{b}{a}x_2$.
  Thus, the solutions to both equations are $(c, -\frac{b}{a}c)$ for any $c$.
  Equivalently, with the solution $x_1^0 = 1$ and $x_2^0 = -\frac{b}{a}$,
  they are all of the form $(yx_1^0, yx_2^0)$ for some scalar $y$, as desired in (c).
\end{prf}

\section{Row-Reduced Echelon Matrices}

\begin{xca}
  Find all solutions to the following system of equations by row-reducing the coefficient matrix:
  \[ \systeme{\frac13x_1 + 2x_2 - 6x_3 = 0, -4x_1 + 5x_3 = 0, -3x_1 + 6x_2 - 13x_3 = 0, -\frac73x_1 + 2x_2 - \frac83x_3 = 0} \]
\end{xca}
\begin{sol}
  Do what the problem says:
  \begin{equation*}
    \begin{split}
      \mqty[\frac13&2&-6 \\ -4&0&5 \\ -3&6&-13 \\ -\frac73&2&-\frac83]
      & \xto{R_1 - R_4} \mqty[\frac83&0&-\frac{10}3 \\ -4&0&5 \\ -3&6&-13 \\ -\frac73&2&-\frac83]
      \xto{R_2 + \frac32 R_1} \mqty[\frac83&0&-\frac{10}3 \\ 0&0&0 \\ -3&6&-13 \\ -\frac73&2&-\frac83] \\
      & \xto{R_3 - 3R_4} \mqty[\frac83&0&-\frac{10}3 \\ 0&0&0 \\ 4&0&-5 \\ -\frac73&2&-\frac83]
      \xto{R_1 - \frac23 R_3} \mqty[0&0&0 \\ 0&0&0 \\ 4&0&-5 \\ -\frac73&2&-\frac83]
      \xto{R_4 + \frac7{12} R_3} \mqty[0&0&0 \\ 0&0&0 \\ 4&0&-5 \\ 0&2&-\frac{67}{12}] \\
      & \xto{\frac14 R_3}
      \xto{\frac12 R_4} \mqty[0&0&0 \\ 0&0&0 \\ 1&0&-\frac52 \\ 0&1&-\frac{67}{24}]
      \xto{R_1 \harr R_3}
      \xto{R_2 \harr R_4} \mqty[1&0&-\frac52 \\ 0&1&-\frac{67}{24} \\ 0&0&0 \\ 0&0&0]
    \end{split}
  \end{equation*}
  Therefore, $x_1 = \frac52 x_3$ and $x_2 = \frac{67}{24} x_3$,
  so for any scalar $c$, there is a solution $(\frac52c, \frac{67}{24}c, c)$.
\end{sol}

\begin{xca}
  Find a row-reduced echelon matrix which is row-equivalent to \[ A = \mqty[1&-i \\ 2&2 \\ i&1+i]. \]
  What are the solutions of $AX = 0$?
\end{xca}
\begin{sol}
  We have:
  \begin{equation*}
    \begin{split}
      A & \xto{R_2 - 2R_1} \mqty[1&-i \\ 0&2-2i \\ i&1+i]
      \xto{R_3 - \frac{i}{2}R_2} \mqty[1&-i \\ 0&2-2i \\ i&0]
      \xto{\frac{1+i}{4}R_2}
      \xto{-iR_3} \mqty[1&-i \\ 0&1 \\ 1&0] \\
      & \xto{R_1 - R_3}
      \xto{R_1 + iR_2} \mqty[0&0 \\ 0&1 \\ 1&0]
      \xto{R_1 \harr R_3} \mqty[1&0 \\ 0&1 \\ 0&0]
    \end{split}
  \end{equation*}
  Therefore, the only solution is the trivial one where $X$ is the zero vector.
\end{sol}

\begin{xca}
  Describe explicitly all $2 \times 2$ row-reduced echelon matrices.
\end{xca}
\begin{prf}
  Trivially, the zero matrix is in row-reduced echelon form.

  If only one entry is non-zero, then row multiplication gives $\mqty[1&0\\0&0]$ or $\mqty[0&1\\0&0]$.

  If two diagonal entries are non-zero, row multiplication and interchange gives $I$.

  If three entries are non-zero and the zero entry is in the bottom-right, row reduction gives
  \begin{equation*}
    \mqty[a&b \\ c&0] \xto{R_2 - \frac{c}{a}R_1} \mqty[a&b \\ 0&0] \xto{\frac{1}{a}R_2} \mqty[1&\frac{b}{a} \\ 0&0]
  \end{equation*}
  The other three cases likewise reduce to $I$.

  Therefore, $2 \times 2$ row-reduced echelon matrices are $0$, $I$,
  or $\mqty[1&c \\ 0&0]$ for some scalar $c$.
\end{prf}

\begin{xca}
  Consider the system of equations
  \[ \systeme{x_1 - x_2 + 2x_3 = 1, 2x_1 + 2x_3 = 1, x_1 - 3x_2 + 4x_3 = 2} \]
  Does this system have a solution? If so, describe explicitly all solutions.
\end{xca}
\begin{prf}
  We row-reduce the augmented matrix of the system:
  \begin{equation*}
    \begin{split}
      \mqty[1&-1&2&1 \\ 2&0&2&1 \\ 1&-3&4&2]
      & \xto{R_2 - R_1} \mqty[1&-1&2&1 \\ 1&1&0&0 \\ 1&-3&4&2]
      \xto{R_3 - 2R_1} \mqty[1&-1&2&1 \\ 1&1&0&0 \\ -1&-1&0&0] \\
      & \xto{R_3 + R_2} \mqty[1&-1&2&1 \\ 1&1&0&0 \\ 0&0&0&0]
      \xto{R_1 + R_2} \mqty[2&0&2&1 \\ 1&1&0&0 \\ 0&0&0&0] \\
      & \xto{\frac12 R_1} \mqty[1&0&1&\frac12 \\ 1&1&0&0 \\ 0&0&0&0]
      \xto{R_2 - R_1} \mqty[1&0&1&\frac12 \\ 0&1&-1&-\frac12 \\ 0&0&0&0]
    \end{split}
  \end{equation*}
  Therefore, $x_1 + x_3 = \frac12$ and $x_2 - x_3 = -\frac12$.
  Solving this system, $x_1 = -x_2$ and $x_3 = x_2 + \frac12$.
  Thus, we have the solution set $(-c,c,c+\frac12)$ for all $c$.
\end{prf}

\begin{xca}
  Give an example of a system of two linear equations in two unknowns which has no solution.
\end{xca}
\begin{sol}
  The system $x_1 + x_2 = 1$ and $x_1 + x_2 = 2$ has no solution, since $1 \neq 2$.
\end{sol}

\begin{xca}
  Show that the system
  \[ \systeme{x_1 - 2x_2 + x_3 + 2x_4 = 1, x_1 + x_2 - x_3 + x_4 = 2, x_1 + 7x_2 - 5x_3 - x_4 = 3} \]
  has no solution.
\end{xca}
\begin{prf}
  We apply elementary row operations to the augmented matrix of the system:
  \begin{equation*}
    \mqty[1&-2&1&2&1 \\ 1&1&-1&1&2 \\ 1&7&-5&-1&3]
    \xto{R_3 - R_2}
    \xto{R_2 - R_1}
    \xto{R_3 - 2R_2} \mqty[1&-2&1&2&1 \\ 0&3&-2&-1&1 \\ 0&0&0&0&-1]
  \end{equation*}
  Clearly, $0 \neq -1$, so there are no solutions to this system.
\end{prf}

\begin{xca}
  Find all solutions of
  \[
    \systeme{
      2x_1 - 3x_2 - 7x_3 + 5x_4 + 2x_5 = -2,
      x_1 - 2x_2 - 4x_3 + 3x_4 + x_5 = -2,
      2x_1 - 4x_3 + 2x_4 + x_5 = 3,
      x_1 - 5x_2 - 7x_3 + 6x_4 + 2x_5 = -7
    }
  \]
\end{xca}
\begin{sol}
  Row-reduce the (very big) augmented matrix of the system:
  \begin{equation*}
    \begin{split}
      & \mqty[2&-3&-7&5&2&-2 \\ 1&-2&-4&3&1&-2 \\ 2&0&-4&2&1&3 \\ 1&-5&-7&6&2&-7]
      \xto{R_1 - R_4} \mqty[1&2&0&-1&0&5 \\ 1&-2&-4&3&1&-2 \\ 2&0&-4&2&1&3 \\ 1&-5&-7&6&2&-7] \\
      & \xto{R_2 - R_3} \mqty[1&2&0&-1&0&5 \\ -1&-2&0&1&0&-5 \\ 2&0&-4&2&1&3 \\ 1&-5&-7&6&2&-7]
      \xto{R_2 + R_1} \mqty[1&2&0&-1&0&5 \\ 0&0&0&0&0&0 \\ 2&0&-4&2&1&3 \\ 1&-5&-7&6&2&-7] \\
      & \xto{R_4 - R_1} \mqty[1&2&0&-1&0&5 \\ 0&0&0&0&0&0 \\ 2&0&-4&2&1&3 \\ 0&-7&-7&7&2&12]
      \xto{R_3 - 2R_1} \mqty[1&2&0&-1&0&5 \\ 0&0&0&0&0&0 \\ 0&-4&-4&4&1&-7 \\ 0&-7&-7&7&2&12] \\
      & \xto{R_3 - \frac47 R_4} \mqty[1&2&0&-1&0&5 \\ 0&0&0&0&0&0 \\ 0&0&0&0&-\frac17&-\frac17 \\ 0&-7&-7&7&2&12]
      \xto{-7R_3} \xto{R_4 - 2R_3} \xto{-\frac17 R_4}
      \mqty[1&2&0&-1&0&5 \\ 0&0&0&0&0&0 \\ 0&0&0&0&1&1 \\ 0&1&1&-1&0&2] \\
      & \xto{R_1 - 2R_4} \xto{R_2 \harr R_4}
      \mqty[1&0&-2&1&0&1 \\ 0&1&1&-1&0&2 \\ 0&0&0&0&1&1 \\ 0&0&0&0&0&0]
    \end{split}
  \end{equation*}
  Therefore, $x_1 = 2x_3 - x_4 + 1$, $x_2 = -x_3 + x_4 + 2$, and $x_5 = 1$.
  The solutions are $(2c_1 - c_2 + 1, c_2 - c_1 + 2, c_1, c_2, 1)$ for arbitrary $c_1$ and $c_2$.
\end{sol}

\begin{xca}
  Let $A = \mqty[3&-1&2 \\ 2&1&1 \\ 1&-3&0]$.

  For which triples $(y_1, y_2, y_3)$ does the system $AX = Y$ have a solution?
\end{xca}
\begin{sol}
  We row-reduce the coefficient matrix:
  \begin{equation*}
    \begin{split}
      & \mqty[3&-1&2 \\ 2&1&1 \\ 1&-3&0]
      \xto{R_1 - 3R_3} \mqty[0&8&2 \\ 2&1&1 \\ 1&-3&0]
      \xto{R_2 - 2R_3} \mqty[0&8&2 \\ 0&7&1 \\ 1&-3&0]
      \xto{R_1 - R_2} \mqty[0&1&1 \\ 0&7&1 \\ 1&-3&0] \\
      & \xto{R_2 - 7R_1} \xto{-\frac16 R_2} \mqty[0&1&1 \\ 0&0&1 \\ 1&-3&0]
      \xto{R_1 - R_2} \xto{R_3 + 3R_1} \mqty[0&1&0 \\ 0&0&1 \\ 1&0&0]
    \end{split}
  \end{equation*}
  If we apply the same elementary row operations to the matrix $Y$,
  we obtain $X$ in terms of $y_1$, $y_2$, and $y_3$.

  Therefore, solutions exist for any triple $(y_1, y_2, y_3)$.
\end{sol}

\begin{xca}
  Let $A = \mqty[3&-6&2&-1 \\ -2&4&1&3 \\ 0&0&1&1 \\ 1&-2&1&0]$.

  For which $(y_1, y_2, y_3, y_4)$ does the system of equations $AX = Y$ have a solution?
\end{xca}
\begin{sol}
  As above, row-reduce $A$:
  \begin{equation*}
    \begin{split}
      & \mqty[3&-6&2&-1 \\ -2&4&1&3 \\ 0&0&1&1 \\ 1&-2&1&0]
      \xto{R_1 - 3R_4} \mqty[0&0&-1&-1 \\ -2&4&1&3 \\ 0&0&1&1 \\ 1&-2&1&0]
      \xto{R_2 + 2R_4} \mqty[0&0&-1&-1 \\ 0&0&3&3 \\ 0&0&1&1 \\ 1&-2&1&0] \\
      & \xto{R_1 + R_3} \xto{R_2 - 3R_3} \mqty[0&0&0&0 \\ 0&0&0&0 \\ 0&0&1&1 \\ 1&-2&1&0]
      \xto{R_4 - R_3} \mqty[0&0&0&0 \\ 0&0&0&0 \\ 0&0&1&1 \\ 1&-2&0&-1]
    \end{split}
  \end{equation*}
  Applying the same operations to the matrix $Y = \mqty[y_1\\y_2\\y_3\\y_4]$,
  we get $\mqty[y_1 + y_3 - 3y_4 \\ y_2 - 3y_3 + 2y_4 \\ y_3 \\ y_4 - y_3]$.

  Therefore, we have solutions when $y_1 + y_3 - 3y_4 = 0$ and $y_2 - y_3 + 2y_4 = 0$.
  Explicitly, there is a solution $(3y_4-y_3, y_3-2y_4, y_3, y_4)$ for every $y_3$ and $y_4$.
\end{sol}

\begin{xca}
  Suppose $R$ and $R'$ are $2 \times 3$ row-reduced echelon matrices
  and that the systems $RX = 0$ and $R'X = 0$ have the same solutions.
  Prove that $R = R'$.
\end{xca}
% TODO: 1.4.10

\section{Matrix Multiplication}

Even though Hoffman \& Kunze define matrix multiplication in summation notation,
I use the ``column vector'' (loosly, since vectors are not introduced until Chapter 2) definition
from Wolczuk's MATH 136 Course Notes to avoid confusing myself.

These are shown to be equivalent in \Cref{xca:vecmult} anyways.

\begin{xca}
  Let $A = \mqty[2&-1&1 \\ 1&2&1]$, $B = \mqty[3\\1\\-1]$, and $C = \mqty[1&-1]$.

  Compute $ABC$ and $CAB$.
\end{xca}
\begin{sol}
  We have $BC = \mqty[3&-3 \\ 1&-1 \\ -1&1]$.
  Then, $ABC = \mqty[A\mqty[3\\1\\-1] & A\mqty[-3\\-1\\1]] = \mqty[4&-4 \\ 4&-4]$.

  Likewise, $AB = \mqty[4\\4]$, so $CAB = \mqty[4-4] = \mqty[0]$.
\end{sol}

\begin{xca}\label{xca:152}
  Let $A = \mqty[1&-1&1 \\ 2&0&1 \\ 3&0&1]$ and $B = \mqty[2&-2 \\ 1&3 \\ 4&4]$.

  Verify directly that $A(AB) = A^2B$.
\end{xca}
\begin{sol}
  On the left-hand side, $AB = \mqty[A\mqty[2\\1\\4] & A\mqty[-2\\3\\4]] = \mqty[5&-1 \\ 8&0 \\ 10&-2]$.

  Then, $A(AB) = \mqty[A\mqty[5\\8\\10] & A\mqty[-1\\0\\2]] = \mqty[7&-3 \\ 20&-4 \\ 25&-5]$.

  On the right-hand side, $A^2 = \mqty[A\mqty[1\\2\\3] & A\mqty[-1\\0\\0] & A\mqty[1\\1\\1]] = \mqty[2&-1&1 \\ 5&-2&3 \\ 6&-3&4]$.

  Then, $A^2B = \mqty[A^2\mqty[2\\1\\4] & A^2\mqty[-2\\3\\4]] = \mqty[7&-3 \\ 20&-4 \\ 25&-5]$.

  The calculations agree.
\end{sol}

\begin{xca}
  Find two different $2 \times 2$ matrices $A$ such that $A^2 = 0$ but $A \neq 0$.
\end{xca}
\begin{sol}
  For some matrix $\mqty[a&b\\c&d]$, its square is $\mqty[a^2+bc&ac+cd\\ab+bd&bc+d^2]$.

  All four of these quantities contain factors of $a$, $b$, or $d$.
  Therefore, we can set $a = 0$, $b = 0$, and $d = 0$ while leaving $c$ arbitrarily non-zero.

  Two examples of this are $\mqty[0&0\\1&0]$ and $\mqty[0&0\\2&0]$.
\end{sol}

\begin{xca}
  For the matrix $A$ of \Cref{xca:152}, find elementary matrices $E_1, E_2, \dotsc E_k$
  such that $E_k \dotsm E_2 E_1 A = I$.
\end{xca}
\begin{sol}
  Recall from Theorem 1.9 that every elementary row operation is equivalent to multiplication
  by an elementary matrix.
  We row-reduce $A$ to the identity matrix, then list the equivalent matrices:
  \begin{equation*}
    \begin{split}
      & \mqty[1&-1&1 \\ 2&0&1 \\ 3&0&1]
      \xto{R_2 - 2R_1} \mqty[1&-1&1 \\ 0&2&-1 \\ 3&0&1]
      \xto{R_3 - 3R_1} \mqty[1&-1&1 \\ 0&2&-1 \\ 0&3&-2]
      \xto{R_3 - R_2} \mqty[1&-1&1 \\ 0&2&-1 \\ 0&1&0] \\
      & \xto{R_2 - 2R_3} \mqty[1&-1&1 \\ 0&0&-1 \\ 0&1&0]
      \xto{-R_2} \mqty[1&-1&1 \\ 0&0&1 \\ 0&1&0]
      \xto{R_2 \harr R_3} \mqty[1&-1&1 \\ 0&1&0 \\ 0&0&1]
      \xto{R_1 - R_3} \xto{R_1 + R_2} I
    \end{split}
  \end{equation*}
  Then, we have the elementary matrix multiplication
  \begin{equation*}
    \smqty[1&1&0\\0&1&0\\0&0&1]\smqty[1&0&-1\\0&1&0\\0&0&1]\smqty[1&0&0\\0&0&1\\0&1&0]
    \smqty[1&0&0\\0&-1&0\\0&0&1]\smqty[1&0&0\\0&1&-2\\0&0&1]\smqty[1&0&0\\0&1&0\\0&-1&1]
    \smqty[1&0&0\\0&1&0\\-3&0&1]\smqty[1&0&0\\-2&1&0\\0&0&1]A = I \qedhere
  \end{equation*}
\end{sol}

\begin{xca}
  Let $A = \mqty[1&-1\\2&2\\1&0]$ and $B = \mqty[3&1\\4&-4]$.

  Is there a matrix $C$ such that $CA = B$?
\end{xca}
\begin{sol}
  The matrix $C$, if it exists, must be $3 \times 2$. Then,
  \[ \mqty[a&b&c\\d&e&f]\mqty[1&-1\\2&2\\1&0] = \mqty[a+2b+c&-a+2b\\d+2e+f&-d+2e] = \mqty[3&1\\4&-4] \]
  We solve two systems of linear equations:
  \[ \systeme{a+2b+c=3,-a+2b=1} \qq{and} \systeme{d+2e+f=4,-d+2e=-4} \]
  These are pretty simple and can be solved by inspection.
  For arbitrary $a$ and $d$, we have $b = \frac{1+a}{2}$, $c = 2-2a$, $e = \frac{d-4}{2}$, and $f = 8-2d$.
  We pick a matrix $C$ with $a = d = 0$ and verify that
  \[ \mqty[0&\frac12&2\\0&-2&8]\mqty[1&-1\\2&2\\1&0] = \mqty[3&1\\4&-4] \]
  as desired.
\end{sol}

\begin{xca}\label{xca:vecmult}
  Let $A$ be an $m \times n$ matrix and $B$ an $n \times k$ matrix.
  Show that the columns of $C = AB$ are linear combinations of the columns of $A$.
  If $\alpha_1,\dotsc,\alpha_n$ are the columns of $A$ and $\gamma_1,\dotsc,\gamma_k$ are the columns of $C$,
  then \[ \gamma_i = \sum_{r=1}^n B_{rj}\alpha_r. \]
\end{xca}
\begin{prf}
  We are essentially asking to equate the standard definition of matrix multiplication with
  the column vector-wise one from MATH 136.

  We have that $C_{ij} = \sum_{r=1}^n A_{ir}B_{rj}$.
  Then, by properties of matrix addition and matrix-scalar multiplication,
  \begin{equation*}
    \gamma_j = \mqty[C_{0j} \\ C_{1j} \\ \vdots \\ C_{kj}]
    = \mqty[\sum_{r=1}^n A_{0r}B_{rj} \\ \sum_{r=1}^n A_{1r}B_{rj} \\ \vdots \\ \sum_{r=1}^n A_{kr}B_{rj}]
    = \sum_{r=1}^n B_{rj} \mqty[A_{0r} \\ A_{1r} \\ \vdots \\ A_{kr}]
    = \sum_{r=1}^n B_{rj} \alpha_r
  \end{equation*}
  as desired.
\end{prf}

% \begin{xca}
%   Let $A$ and $B$ be $2 \times 2$ matrices such that $AB = I$. Prove that $BA = I$.
% \end{xca}
% TODO: 1.5.7 (follows from invertability but idk how to do otherwise)

% \begin{xca}
%   Let \[ C = \mqty[C_{11}&C_{12}\\C_{21}&C_{22}] \] be a $2 \times 2$ matrix.
%   We inquire when it is possible to find $2 \times 2$ matrices $A$ and $B$ such that $C = AB - BA$.
%   Prove that such matrices can be found if and only if $C_{11} + C_{22} = 0$.
% \end{xca}
% TODO: 1.5.8

\section{Invertible Matrices}

\begin{xca}\label{xca:rpa}
  Let $A = \mqty[1&1&1&0 \\ -1&0&3&5 \\ 1&-2&1&1]$.

  Find a row-reduced echelon matrix $R$ which is row-equivalent to $A$
  and an invertible $3 \times 3$ matrix $P$ such that $R = PA$.
\end{xca}
\begin{sol}
  We row-reduce the matrix $A$, repeating the operations with $I$:
  \begin{equation*}
    \begin{split}
      & \bmqty[cccc|ccc]{1&2&1&0 & 1&0&0 \\ -1&0&3&5 & 0&1&0 \\ 1&-2&1&1 & 0&0&1}
      \to \bmqty[cccc|ccc]{1&0&-3&-5 & 0&-1&0 \\ 1&-2&1&1 & 0&0&1 \\ 1&2&1&0 & 1&0&0} \\
      & \to \bmqty[cccc|ccc]{1&0&-3&-5 & 0&-1&0 \\ 0&-2&4&6 & 0&1&1 \\ 0&2&4&5 & 1&1&0}
      \to \bmqty[cccc|ccc]{1&0&-3&-5 & 0&-1&0 \\ 0&1&-2&-3 & 0&-\frac12&-\frac12 \\ 0&0&8&11 & 1&2&1} \\
      & \to \bmqty[cccc|ccc]{1&0&0&-\frac78 & \frac38&-\frac14&\frac38 \\ 0&1&0&-\frac14 & \frac14&0&-\frac14 \\ 0&0&1&\frac{11}8 & \frac18&\frac14&\frac18}
    \end{split}
  \end{equation*}
  Therefore, we let $R = \mqty[\mqty{\imat{3}} & \mqty{-\frac78\\-\frac14\\\frac{11}8}]$,
  and $P = \mqty[\frac38&-\frac14&\frac38 \\ \frac14&0&-\frac14 \\ \frac18&\frac14&\frac18]$.
  It follows that $R = PA$, and as a product of invertible elementary matrices, $P$ is invertible.
\end{sol}

\begin{xca}
  Do \Cref{xca:rpa}, but with $A = \mqty[2&0&i \\ 1&-3&-i \\ i&1&1]$
\end{xca}
\begin{sol}
  Again, we perform row-reduction alongside $I$:
  \begin{equation*}
    \begin{split}
      & \bmqty[ccc|ccc]{2&0&i & 1&0&0 \\ 1&-3&-i & 0&1&0 \\ i&1&1 & 0&0&1}
      \to \bmqty[ccc|ccc]{1&0&\frac12i & \frac12&0&0 \\ 1&-3&-i & 0&1&0 \\ i&1&1 & 0&0&1}
      \to \bmqty[ccc|ccc]{1&0&\frac12i & \frac12&0&0 \\ 0&-3&-\frac32i & -\frac12&1&0 \\ 0&1&1-\frac12i & -\frac12i&0&1} \\
      & \to \bmqty[ccc|ccc]{1&0&\frac12i & \frac12&0&0 \\ 0&0&3-3i & -\frac12+\frac32i&1&3 \\ 0&1&1-\frac12i & -\frac12i&0&1}
      \to \bmqty[ccc|ccc]{1&0&\frac12i & \frac12&0&0 \\ 0&0&1 & -\frac13+\frac16i&\frac16+\frac16i&\frac12+\frac12i \\ 0&1&1-\frac12i & -\frac12i&0&1} \\
      & \to \bmqty[ccc|ccc]{
        1&0&0 & \frac13&\frac1{30}-\frac1{10}i&\frac1{10}-\frac3{10}i \\
        0&1&0 & 0&-\frac3{10}-\frac1{10}i&\frac1{10}-\frac3{10}i \\
        0&0&1 & -\frac13i&\frac15-\frac1{15}i&\frac35+\frac15i
      } \qedhere
    \end{split}
  \end{equation*}
\end{sol}

\begin{xca}
  For each of the two matrices
  \[ \mqty[2&5&-1\\4&-1&2\\6&4&1] \qand \mqty[1&-1&2\\3&2&4\\0&-2&1] \]
  use elementary row operations to discover whether it is invertible,
  and to find the inverse in case it is.
\end{xca}
\begin{sol}
  We row-reduce the first matrix:
  \begin{equation*}
    \begin{split}
      & \bmqty[ccc|ccc]{2&5&-1 & 1&0&0 \\ 4&-1&2 & 0&1&0 \\ 6&4&1 & 0&0&1}
      \to \bmqty[ccc|ccc]{2&5&-1 & 1&0&0 \\ 0&-11&4 & -2&1&0 \\ 0&-11&4 & -3&0&1}
      \to \bmqty[ccc|ccc]{2&5&-1 & 1&0&0 \\ 0&-11&4 & -2&1&0 \\ 0&0&0 & -5&-1&1}
    \end{split}
  \end{equation*}
  so the first matrix is not invertible.

  Now, row-reduce the second matrix:
  \begin{equation*}
    \begin{split}
      & \bmqty[ccc|ccc]{1&-1&2 & 1&0&0 \\ 3&2&4 & 0&1&0 \\ 0&-2&1 & 0&0&1}
      \to \bmqty[ccc|ccc]{1&-1&2 & 1&0&0 \\ 0&5&-2 & -3&1&0 \\ 0&-2&1 & 0&0&1}
      \to \bmqty[ccc|ccc]{1&-1&2 & 1&0&0 \\ 0&1&0 & -3&1&2 \\ 0&-2&1 & 0&0&1} \\
      & \to \bmqty[ccc|ccc]{1&-1&2 & 1&0&0 \\ 0&1&0 & -3&1&2 \\ 0&0&1 & -6&2&1}
      \to \bmqty[ccc|ccc]{1&0&0 & 10&-3&8 \\ 0&1&0 & -3&1&2 \\ 0&0&1 & -6&2&5}
    \end{split}
  \end{equation*}
  Therefore, the inverse is $\mqty[10&-3&8 \\ -3&1&2 \\ -6&2&5]$.
\end{sol}

\begin{xca}
  Let $A = \mqty[5&0&0 \\ 1&5&0 \\ 0&1&5]$.

  For which $X$ does there exist a scalar $C$ such that $AX = cX$?
\end{xca}
\begin{sol}
  Perform the generic matrix multiplication:
  \[
    \mqty[5&0&0 \\ 1&5&0 \\ 0&1&5] \mqty[x \\ y \\ z]
    = \mqty[5x \\ x+5y \\ y+5z] = c\mqty[x \\ y \\ z]
  \]
  Now, element-wise, if $c = 5$, then $x+5y=5y$ so $x=0$ but $y+5z=5z$ so $y=0$.
  Then, $X = (0,0,z)$ for any $z$.
  Otherwise, $5x = cx$ so $c=0$ and everything goes to zero, so we have $X=(0,0,0)$.

  Therefore, $X = (0,0,z)$ for any $z$.
\end{sol}

% TODO: 1.6.5-1.6.12

\chapter{Vector Spaces}

\section{Vector Spaces}

\begin{xca}\label{xca:211}
  If $F$ is a field, verify that $F^n$ is a vector space over $F$.
\end{xca}
\begin{prf}
  Let $\alpha = (a_1,\dotsc,a_n)$, $\beta = (b_1,\dotsc,b_n)$,
  $\gamma = (c_1,\dotsc,c_n)$, and $k$, $l$ be in $F$.
  Then we can verify the axioms for vector addition:
  \begin{enumerate}[(a)]
    \item $\alpha + \beta = (a_1+b_1,\dotsc,a_n+b_n) = (b_1+a_1,\dotsc,b_n+a_n) = \beta + \alpha$
    \item $\alpha + (\beta + \gamma) = (a_1+(b_1+c_1),\dotsc,a_n+(b_n+c_n)) = ((a_1+b_1)+c_1,\dotsc,(a_n+b_n)+c_n) = (\alpha + \beta) + \gamma$
    \item Let $0 = (0,\dotsc,0)$, then $\alpha+0 = (a_1+0,\dotsc,a_n+0) = \alpha$
    \item Let $-\alpha = (-a_1,\dotsc,-a_n)$, then $\alpha+(-\alpha) = (a_1-a_1,\dotsc,a_n-a_n) = 0$
  \end{enumerate}
  and for vector multiplication:
  \begin{enumerate}[(a)]
    \item $1\alpha = (1a_1,\dotsc,1a_n) = (a_1,\dotsc,a_n) = \alpha$
    \item $(k l)\alpha = (k l a_1,\dotsc,k_1 k_2 a_n) = (k(l a_1),\dotsc,k_1(k_2 a_n)) = k(l\alpha)$
    \item $k(\alpha+\beta) = (k(a_1+b_1),\dotsc,k(a_n+b_n)) = (ka_1+kb_1,\dotsc,ka_n+kb_n) = (ka_1,\dotsc,ka_n) + (kb_1,\dotsc,kb_n) = k\alpha + k\beta$
    \item $(k+l)\alpha = ((k+l)a_1,\dotsc,(k+l)a_n) = (ka_1+la_1,\dotsc,ka_n+la_n) = k\alpha + l\alpha$
  \end{enumerate}
  Since they are all satisfied, $F^n$ is a vector space over $F$.
\end{prf}

\begin{xca}
  If $V$ is a vector space over the field $F$, verify that
  \[ (\alpha_1 + \alpha_2) + (\alpha_3 + \alpha_4) = [\alpha_2 + (\alpha_3 + \alpha_1)] + \alpha_4 \]
  for all vectors $\alpha_1,\alpha_2,\alpha_3,$ and $\alpha_4$ in $V$.
\end{xca}
\begin{prf}
  We apply the properties of vector addition:
  \begin{align*}
    (\alpha_1 + \alpha_2) + (\alpha_3 + \alpha_4)
     & = (\alpha_2 + \alpha_1) + (\alpha_3 + \alpha_4)          \\
     & = [(\alpha_2 + \alpha_1) + \alpha_3] + \alpha_4          \\
     & = [\alpha_2 + (\alpha_1 + \alpha_3)] + \alpha_4          \\
     & = [\alpha_2 + (\alpha_3 + \alpha_1)] + \alpha_4 \qedhere
  \end{align*}
\end{prf}

\begin{xca}
  If $C$ is the field of complex numbers, which vectors $C^3$ are linear combinations
  of $(1,0,-1)$, $(0,1,1)$, and $(1,1,1)$.
\end{xca}
\begin{sol}
  Notice that the matrix is invertible:
  \[ \mqty[1&0&1\\0&1&1\\-1&1&1] \to \mqty[1&0&-1\\0&1&1\\1&0&0] \to \mqty[1&0&0\\0&1&0\\0&0&1] \]
  Therefore, for any vector $Y$, we can find a vector $AX = Y$ by $A^{-1}Y$.
\end{sol}

\begin{xca}
  Let $V$ be the set of all pairs $(x,y)$ of real numbers,
  and let $F$ be the field of real numbers.
  Define $(x,y) + (x_1,y_1) = (x+x_1,y+y_1)$ and $c(x,y) = (cx,y)$.
  Is $V$, with these operations, a vector space over the field of real numbers?
\end{xca}
\begin{sol}
  This is not a vector space.
  Notice that $(1+1)(x,y) = 2(x,y) = (2x,y)$
  but $1(x,y) + 1(x,y) = (x,y) + (x,y) = (2x,2y)$.
\end{sol}

\begin{xca}
  On $R^n$, define two operations $\alpha \oplus \beta = \alpha - \beta$
  and $c\cdot\alpha = -c\alpha$.
  Which of the axioms for a vector space are satisfied by $(R^n,\oplus,\cdot)$?
\end{xca}
\begin{sol}
  Notice that $\oplus$ is not commutative:
  $\alpha \oplus \beta = \alpha - \beta = -(\beta - \alpha) = -(\beta \oplus \alpha)$.

  It is not associative:
  $\alpha \oplus (\beta \oplus \gamma) = \alpha - (\beta - \gamma)
    = (\alpha - \beta) - (-\gamma) = (\alpha \oplus \beta) \oplus (-\gamma)$.

  We have the usual 0 element: $\alpha \oplus (0,\dotsc,0) = (a_1-0,\dotsc,a_n-0) = \alpha$.

  Everything is its (unique) additive inverse: $\alpha \oplus \alpha = \alpha - \alpha = 0$.

  Now, $\cdot$ has an identity ($-1$) but it is not 1: $1\cdot\alpha = -\alpha$.

  It is associative: $(c_1c_2)\cdot\alpha = -c_1c_2\alpha = c_1(-c_2\alpha) = c_1\cdot(c_2\alpha)$.

  It distributes over $\oplus$:
  $c\cdot(\alpha \oplus \beta) = -c(\alpha - \beta) = (-c\alpha) - (-c\beta) = c\cdot\alpha \oplus c\cdot\beta$.

  It does not distribute over $+$:
  $(c_1+c_2)\cdot\alpha = -(c_1+c_2)\alpha = -c_1\alpha - c_2\alpha = c_1\cdot\alpha \oplus (-c_2)\cdot\alpha$.
\end{sol}

\begin{xca}
  Let $V$ be the set of all complex-valued functions $f$ on the real line
  such that for all $t$ in $R$, $f(-t) = \overline{f(t)}$.
  Show that $V$, with the operations $(f+g)(t) = f(t)+g(t)$ and $(cf)(t) = c f(t)$
  is a vector space over the field of real numbers.
  Give an example of a function in $V$ which is not real-valued.
\end{xca}
\begin{prf}
  Let $O(t) = 0$.
  We can satisfy the vector addition axioms:
  \begin{gather*}
    (f+g)(t) = f(t) + g(t) = g(t) + f(t) = (g+f)(t) \\
    ((f+g)+h)(t) = (f+g)(t) + h(t) = f(t) + g(t) + h(t) = f(t) + (g+h)(t) = (f+(g+h))(t) \\
    (f+O)(t) = f(t) + O(t) = f(t) + 0 = f(t) \\
    (f + (-f))(t) = f(t) + (-f(t)) = 0 = O(t)
  \end{gather*}
  and the scalar multiplication axioms:
  \begin{gather*}
    (1f)(t) = 1f(t) = f(t) \\
    (c_1c_2f)(t) = c_1c_2f(t) = c_1(c_2f)(t) = (c_1(c_2f))(t) \\\
    (c(f+g))(t) = c(f+g)(t) = c(f(t)+g(t)) = cf(t) + cg(t) = (cf)(t) + (cg)(t) = (cf+cg)(t) \\
    ((c_1+c_2)f)(t) = (c_1+c_2)f(t) = c_1f(t) + c_2f(t) = (c_1f)(t) + (c_2f)(t) = (c_1f+c_2f)(t)
  \end{gather*}
  which verifies that $V$ is a vector space.

  As an example, $f(t) = it$ is in $V$, since $f(-t) = -it = \overline{it} = \overline{f(t)}$.
\end{prf}

\begin{xca}
  Let $V$ be the set of pairs $(x,y)$ of real numbers
  and let $F$ be the field of real numbers.

  Define $(x,y) + (x_1,y_1) = (x+x_1,0)$ and $c(x,y) = (cx,0)$.

  Is $V$, with these operations, a vector space?
\end{xca}
\begin{sol}
  No. Notice that since $c(x,y) = (cx,0)$,
  there does not exist a multiplicative identity $c$
  such that $c(x,y) = (x,y)$ for non-zero $y$.
\end{sol}

\setcounter{chapter}{7}
\chapter{Inner Product Spaces}

\section{Inner Products}

Notational note: Hoffman \& Kunze use the notation $\ip{\alpha}{\beta}$ for the inner product of vectors $\alpha$ and $\beta$,
whereas Wolczuk would prefer $\ev{\vb{a}, \vb{b}}$ for vectors $\vb a$ and $\vb b$.

\begin{xca}
  Let $V$ be a vector space and $\ip{\quad}$ an inner product on $V$.
  Show that (a) $\ip{0}{\beta}=0$ for all $\beta$ in $V$ and (b) if $\ip{\alpha}{\beta} = 0$ for all $\beta$ in $V$, then $\alpha = 0$.
\end{xca}
\begin{prf}
  For the first part, let $\alpha$ and $\beta \in V$.
  Consider the quantity $\ip{0\alpha}{\beta}$.
  It follows from linearity that $0\ip{\alpha}{\beta} = \ip{0}{\beta} = 0$.

  Now, suppose that $\ip{\alpha}{\beta} = 0$.
  Indeed, as $\beta$ is arbitrary, this holds when $\beta = \alpha$.
  Then, $\ip{\alpha} = 0$.
  However, since inner products are positive definite, $\alpha = 0$.
\end{prf}

\begin{xca}
  Let $V$ be a vector space over $F$.
  Show that the sum of two inner products on $V$ is an inner product on $V$.
  Is the difference of two inner products an inner product?
  Show that a positive multiple of an inner product is an inner product.
\end{xca}
\begin{prf}
  Let $p_1(\alpha,\beta)$ and $p_2(\alpha,\beta)$ be inner products on $V$.

  Now, let $s(\alpha,\beta) = p_1(\alpha, \beta) + p_2(\alpha, \beta)$.
  Then, we show the axioms of an inner product:
  \begin{align*}
    s(\alpha+\beta,\gamma)
     & = p_1(\alpha+\beta,\gamma)+p_2(\alpha+\beta,\gamma)                                   \\
     & = p_1(\alpha,\gamma) + p_1(\beta,\gamma) + p_2(\alpha,\gamma) + p_2(\beta,\gamma)     \\
     & = (p_1(\alpha,\gamma) + p_2(\alpha,\gamma)) + (p_1(\beta,\gamma) + p_2(\beta,\gamma)) \\
     & = s(\alpha,\gamma) + s(\beta,\gamma)                                                  \\
    s(c\alpha, \beta)
     & = p_1(c\alpha, \beta) + p_2(c\alpha, \beta)                                           \\
     & = cp_1(\alpha,\beta) + cp_2(\alpha,\beta)                                             \\
     & = cs(\alpha,\beta)                                                                    \\
    s(\beta,\alpha)
     & = p_1(\beta,\alpha) + p_2(\beta,\alpha)                                               \\
     & = \overline{p_1(\alpha,\beta)} + \overline{p_2(\alpha,\beta)}                         \\
     & = \overline{p_1(\alpha,\beta) + p_2(\alpha,\beta)}                                    \\
     & = \overline{s(\alpha,\beta)}
  \end{align*}
  Finally, the sum of positive values is certainly positive.
  Therefore, $s$ is an inner product.

  Now, the difference of inner products is \emph{not} an inner product.
  If we let the two inner products be the same, the resulting function always produces zero.

  Let $\ip{\quad}$ be an inner product.
  Then, for some positive real $k$:
  \begin{align*}
    k\ip{\alpha+\beta}{\gamma} & = k(\ip{\alpha}{\gamma}+\ip{\beta}{\gamma}) = k\ip{\alpha}{\gamma} + k\ip{\beta}{\gamma} \\
    k\ip{c\alpha}{\beta}       & = k(c\ip{\alpha}{\beta}) = c(k\ip{\alpha}{\beta})                                        \\
    k\ip{\beta}{\alpha}        & = k\overline{\ip{\alpha}{\beta}} = \overline{k\ip{\alpha}{\beta}}
  \end{align*}
  Finally, multiplying two positive values maintains positivity.
\end{prf}

\begin{xca}
  Describe explicitly all inner products on $\R^1$ and on $\C^1$.
\end{xca}
% TODO: 8.1.3 (is it not just multiplication + 8.1.2?)

\begin{xca}
  Verify that the standard inner product on $F^n$ is an inner product.
\end{xca}
\begin{prf}
  Let $\ip{\quad}$ be the standard inner product on $F^n$.
  Then, for vectors $\alpha = (x_1,\dotsc,x_n)$,
  $\beta = (y_1,\dotsc,y_n)$, and $\gamma = (z_1,\dotsc,z_n)$,
  it follows by properties of the summation that
  \[
    \ip{\alpha+\beta}{\gamma} = \sum_{j=1}^k (x_j+y_j)\bar z_j
    = \sum_{j=1}^k x_j \bar z_j + \sum_{j=1}^k y_j \bar z_j
    = \ip{\alpha}{\gamma} + \ip{\beta}{\gamma}
  \]
  and
  \[
    \ip{c\alpha}{\beta} = \sum_{j=1}^k cx_j\bar z_j
    = c\sum_{j=1}^k x_j \bar z_j
    = c\ip{\alpha}{\beta}
  \]
  giving linearity. Conjugate symmetry follows from properties of the conjugate:
  \[
    \ip{\beta}{\alpha} = \sum_{j=1}^k y_j \bar x_j
    = \overline{(\overline{\textstyle\sum_{j=1}^k y_j \bar x_j})}
    = \overline{(\textstyle\sum_{j=1}^k \bar y_j \bar{\bar{x}}_j)}
    = \overline{(\textstyle\sum_{j=1}^k x_j \bar y_j)}
    = \overline{\ip{\alpha}{\beta}}
  \]
  Finally, consider $\ip{\alpha} = \sum_{j=1}^k x_j \bar x_j = \sum_{j=1}^k |x_j|^2$.
  As squares, these terms are all non-negative.
  If $\alpha \neq 0$, then one of the $x_j$ is non-zero for some $j$.
  The sum includes the term $x_j^2 > 0$, so the sum is positive.

  Therefore, the standard inner product on $F^n$ is indeed an inner product.
\end{prf}

\end{document}